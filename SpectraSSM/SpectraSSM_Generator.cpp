
// SpectraSSM - 频域状态空间模型库
// 版权所有 © 2026 SpectraSSM 项目所有者
// 
// 本软件受 SpectraSSM 自定义社区许可协议 v1.0 约束，使用需满足：
// - 年营业额 ≤ 5,000,000 人民币（滚动12个月）
// - 详见完整协议: LICENSE.txt
// 
// 警告：此许可证非开源许可证，包含商业使用限制和审计条款。
// 使用本软件即表示您同意接受所有条款，包括零责任赔偿限制。
//
#include "SpectraSSM_Generator.hpp"
#include <cmath>
#include <algorithm>
#include <stdexcept>
#include <queue>

namespace SpectraSSM {

    // ============================================================
    // 状态空间递归生成器 - 构造函数
    // ============================================================

    状态空间递归生成器::状态空间递归生成器(
        std::shared_ptr<频域MoE模型> 模型,
        int64_t 词汇表大小,
        int64_t 最大序列长度)
        : 模型_(模型), 词汇表大小_(词汇表大小), 最大序列长度_(最大序列长度) {

        // 参数验证
        TORCH_CHECK(模型_ != nullptr, "模型指针不能为空");
        TORCH_CHECK(词汇表大小 > 0, "词汇表大小必须大于0");
        TORCH_CHECK(最大序列长度 > 0 && 最大序列长度 <= 32768,
            "最大序列长度必须在1-32768之间");

        // 从模型中获取维度信息
        auto 配置 = 模型_->获取配置();
        模型维度_ = 配置.at("模型维度");
        状态维度_ = 配置.at("状态维度");

        TORCH_CHECK(模型维度_ > 0 && 状态维度_ > 0, "模型维度配置无效");

        // 初始化输出投影层：将状态维度映射到词汇表大小
        输出投影层_ = register_module(
            "输出投影层_",
            torch::nn::Linear(状态维度_, 词汇表大小_)
        );

        // 初始化嵌入层：将token映射到模型维度
        嵌入层_ = register_module(
            "嵌入层_",
            torch::nn::Embedding(词汇表大小_, 模型维度_)
        );

        // 预计算频域基础缓存
        auto 频率向量 = 模型_->计算频率(最大序列长度_);
        频域基础缓存_ = 频域生成优化器::预计算频域基础(
            最大序列长度_,
            频率向量
        );

        TORCH_INFO("状态空间递归生成器初始化完成");
        TORCH_INFO("模型维度: ", 模型维度_, ", 状态维度: ", 状态维度_);
        TORCH_INFO("词汇表大小: ", 词汇表大小_, ", 最大序列长度: ", 最大序列长度_);
    }

    // ============================================================
    // 束搜索生成 - 主入口
    // ============================================================

    torch::Tensor 状态空间递归生成器::束搜索生成(
        const torch::Tensor& 输入前缀,
        const 生成配置& 配置) {

        TORCH_CHECK(输入前缀.defined(), "输入前缀未定义");
        TORCH_CHECK(输入前缀.dim() == 2, "输入前缀必须是2维 [批次大小, 前缀长度]");
        TORCH_CHECK(输入前缀.size(0) == 1, "束搜索暂时只支持批次大小为1");

        int64_t 批大小 = 输入前缀.size(0);
        int64_t 前缀长度 = 输入前缀.size(1);

        TORCH_INFO("开始束搜索生成，前缀长度: ", 前缀长度,
            ", 束宽: ", 配置.束宽,
            ", 最大生成: ", 配置.最大生成长度);

        // 1. 初始化生成状态
        auto 初始状态 = 初始化生成状态(输入前缀);
        TORCH_CHECK(初始状态.defined(), "初始状态生成失败");

        // 2. 创建初始假设
        std::vector<生成假设> 当前假设列表;
        生成假设 初始假设;
        初始假设.序列 = 输入前缀;
        初始假设.隐状态 = 初始状态;
        初始假设.对数概率得分 = 0.0f;
        初始假设.已终止 = false;

        // 初始频域缓存设为频域基础缓存的前缀长度部分
        初始假设.频域缓存 = 频域基础缓存_.narrow(0, 0, 前缀长度 / 2 + 1);

        当前假设列表.push_back(std::move(初始假设));

        // 3. 束搜索主循环
        for (int 步骤 = 0; 步骤 < 配置.最大生成长度; ++步骤) {
            // 计算当前步骤的动态束宽
            int 当前束宽 = 计算动态束宽(前缀长度 + 步骤, 前缀长度 + 配置.最大生成长度);

            // 执行束搜索迭代
            auto 新假设列表 = 执行束搜索迭代(当前假设列表, 配置);

            // 按得分排序并选择顶级假设
            std::sort(新假设列表.begin(), 新假设列表.end(),
                [](const 生成假设& a, const 生成假设& b) {
                    return a.对数概率得分 > b.对数概率得分;
                });

            // 修剪到当前束宽
            if (新假设列表.size() > 当前束宽) {
                新假设列表.resize(当前束宽);
            }

            当前假设列表 = std::move(新假设列表);

            // 检查是否所有假设都已终止
            bool 全部终止 = true;
            for (const auto& 假设 : 当前假设列表) {
                if (!假设.已终止) {
                    全部终止 = false;
                    break;
                }
            }

            if (全部终止) {
                TORCH_INFO("所有假设已终止，提前结束生成，步骤: ", 步骤 + 1);
                break;
            }

            // 每50步输出一次进度
            if (步骤 % 50 == 0) {
                TORCH_INFO("生成进度: ", 步骤 + 1, "/", 配置.最大生成长度);
            }
        }

        // 4. 选择最佳假设
        if (当前假设列表.empty()) {
            TORCH_WARN("束搜索未生成任何有效假设");
            return 输入前缀;
        }

        auto 最佳假设 = std::max_element(
            当前假设列表.begin(),
            当前假设列表.end(),
            [](const 生成假设& a, const 生成假设& b) {
                return a.对数概率得分 < b.对数概率得分;
            }
        );

        TORCH_INFO("束搜索完成，最佳得分: ", 最佳假设->对数概率得分,
            ", 最终序列长度: ", 最佳假设->序列.size(1));

        return 最佳假设->序列;
    }

    // ============================================================
    // 贪婪生成 - 单路径快速生成
    // ============================================================

    torch::Tensor 状态空间递归生成器::贪婪生成(
        const torch::Tensor& 输入前缀,
        int 最大生成长度) {

        TORCH_CHECK(输入前缀.defined(), "输入前缀未定义");

        生成配置 配置;
        配置.束宽 = 1;  // 贪婪搜索就是束宽为1的特例
        配置.最大生成长度 = 最大生成长度;
        配置.温度 = 0.0f;  // 贪婪解码不使用温度

        return 束搜索生成(输入前缀, 配置);
    }

    // ============================================================
    // 采样生成 - 基于概率的温度采样
    // ============================================================

    torch::Tensor 状态空间递归生成器::采样生成(
        const torch::Tensor& 输入前缀,
        float 温度,
        int 最大生成长度) {

        TORCH_CHECK(输入前缀.defined(), "输入前缀未定义");
        TORCH_CHECK(温度 >= 0.0f, "温度必须为非负数");

        生成配置 配置;
        配置.束宽 = 1;  // 采样生成使用单路径
        配置.最大生成长度 = 最大生成长度;
        配置.温度 = 温度;

        return 束搜索生成(输入前缀, 配置);
    }

    // ============================================================
    // 初始化生成状态 - 完整前向传播
    // ============================================================

    torch::Tensor 状态空间递归生成器::初始化生成状态(
        const torch::Tensor& 输入前缀) {

        TORCH_CHECK(输入前缀.defined(), "输入前缀未定义");

        // 将输入token转换为嵌入向量
        auto 前缀嵌入 = 嵌入层_(输入前缀);
        TORCH_CHECK(前缀嵌入.defined(), "嵌入层前向传播失败");
        TORCH_CHECK(前缀嵌入.dim() == 3,
            "嵌入输出应为3维 [批次, 序列, 维度]");

        // 使用传入的频域MoE模型进行完整前向传播
        auto 输出状态 = 模型_->前向传播(前缀嵌入);
        TORCH_CHECK(输出状态.defined(), "状态空间前向传播失败");

        // 取最后一个时间步的状态作为初始生成状态
        auto 初始状态 = 输出状态.select(1, -1);  // [批次, 状态维度]

        TORCH_INFO("生成状态初始化完成，状态形状: ", 初始状态.size(0),
            "x", 初始状态.size(1));

        return 初始状态;
    }

    // ============================================================
    // 计算状态转移 - 核心递推方程
    // ============================================================

    torch::Tensor 状态空间递归生成器::计算状态转移(
        const torch::Tensor& 当前状态,
        const torch::Tensor& 输入token) {

        TORCH_CHECK(当前状态.defined() && 输入token.defined(),
            "状态和输入必须定义");
        TORCH_CHECK(当前状态.dim() == 2 && 输入token.dim() == 2,
            "状态和输入必须是2维张量");
        TORCH_CHECK(当前状态.size(0) == 输入token.size(0),
            "状态和输入的批次大小必须相同");

        // 从模型中获取参数
        auto 模型参数 = 模型_->获取命名参数映射();
        auto A_频率 = *(模型参数.at("A_频率"));
        auto B_频率 = *(模型参数.at("B_频率"));

        // 状态转移方程: hₜ = A·hₜ₋₁ + B·xₜ
        // A·hₜ₋₁: [状态维度, 状态维度] × [批, 状态维度] -> [批, 状态维度]
        auto A_h = torch::matmul(当前状态, A_频率.transpose(0, 1));

        // B·xₜ: [批,模型维度] × [模型维度, 状态维度] -> [批, 状态维度]
        auto B_x = torch::matmul(输入token, B_频率);

        // 两者相加得到新状态
        auto 新状态 = A_h + B_x;

        return 新状态;
    }

    // ============================================================
    // 增量频域计算 - 优化性能关键
    // ============================================================

    torch::Tensor 状态空间递归生成器::增量频域计算(
        const torch::Tensor& 新token序列,
        const torch::Tensor& 历史频域缓存) {

        TORCH_CHECK(新token序列.defined(), "新token序列未定义");
        TORCH_CHECK(历史频域缓存.defined(), "历史频域缓存未定义");

        // 利用DFT的线性性质进行增量更新
        // FFT([x₁..xₙ₊₁]) = FFT([x₁..xₙ]) + ΔFFT(xₙ₊₁)

        int64_t 历史长度 = (历史频域缓存.size(0) - 1) * 2;
        int64_t 新增长度 = 新token序列.size(1);

        // 计算新部分的频域表示
        auto 新部分频域 = torch::fft_rfft(新token序列.transpose(1, 2), 新增长度, -1);
        新部分频域 = 新部分频域.transpose(1, 2);

        // 相位调整（关键：考虑时间偏移）
        // 对于新增部分，需要乘以相应的旋转因子 e^(-j·2π·k·历史长度/总长度)
        int64_t 频率数量 = 历史频域缓存.size(0);
        auto 频率索引 = torch::arange(频率数量,
            torch::TensorOptions().dtype(torch::kFloat32)
            .device(新token序列.device()));

        // 修正复数单位定义
        auto j = torch::tensor({ 0.0f, 1.0f },
            torch::TensorOptions().dtype(torch::kComplexFloat).device(新token序列.device()));
        auto 复数单位 = j.sum();  // 创建一个复数标量 (0+1j)

        auto 旋转因子 = torch::exp(-复数单位 * M_PI * 频率索引 * 历史长度 / (历史长度 + 新增长度));

        旋转因子 = 旋转因子.view({ 频率数量, 1, 1 });
        新部分频域 = 新部分频域 * 旋转因子;

        // 合并到历史缓存
        auto 更新后的频域 = 历史频域缓存.clone();
        更新后的频域.narrow(0, 0, 新部分频域.size(0)) += 新部分频域;

        TORCH_INFO("增量频域计算完成，历史长度: ", 历史长度,
            ", 新增长度: ", 新增长度,
            ", 频域缓存形状: ", 更新后的频域.size(0));

        return 更新后的频域;
    }


    // ============================================================
    // 执行束搜索迭代 - 核心算法
    // ============================================================

    std::vector<生成假设> 状态空间递归生成器::执行束搜索迭代(
        const std::vector<生成假设>& 当前假设,
        const 生成配置& 配置) {

        TORCH_CHECK(!当前假设.empty(), "当前假设列表不能为空");

        int 活跃假设数 = 0;
        for (const auto& 假设 : 当前假设) {
            if (!假设.已终止) 活跃假设数++;
        }

        if (活跃假设数 == 0) {
            TORCH_WARN("没有活跃假设，束搜索迭代结束");
            return 当前假设;
        }

        TORCH_INFO("执行束搜索迭代，活跃假设数: ", 活跃假设数,
            ", 当前假设总数: ", 当前假设.size());

        // 1. 收集所有活跃假设的状态和序列
        std::vector<torch::Tensor> 状态列表;
        std::vector<torch::Tensor> 序列列表;

        for (const auto& 假设 : 当前假设) {
            if (!假设.已终止) {
                状态列表.push_back(假设.隐状态);
                序列列表.push_back(假设.序列);
            }
        }

        // 2. 批量计算下一个token的概率分布
        auto 状态张量 = torch::cat(状态列表, 0);  // [活跃假设数, 状态维度]
        auto 概率分布 = 计算下一个token概率(状态张量, 配置);

        TORCH_CHECK(概率分布.dim() == 2,
            "概率分布应为2维 [活跃假设数, 词汇表大小]");
        TORCH_CHECK(概率分布.size(0) == 活跃假设数,
            "概率分布批次大小与活跃假设数不匹配");

        // 3. 对每个假设扩展token
        std::vector<生成假设> 新假设列表;

        for (int i = 0; i < 活跃假设数; ++i) {
            // 获取当前假设（跳过已终止的）
            int 原始索引 = 0;
            while (原始索引 < 当前假设.size() && 当前假设[原始索引].已终止) {
                原始索引++;
            }

            const auto& 当前假设项 = 当前假设[原始索引];

            // 获取当前假设的概率分布
            auto 当前分布 = 概率分布[i];

            // 应用重复惩罚（如果有历史序列）
            if (当前假设项.序列.size(1) > 0) {
                应用重复惩罚(当前分布, 当前假设项.序列);
            }

            // 选择顶级token候选（最多束宽的2倍）
            int 候选数量 = std::min(配置.束宽 * 2, (int)词汇表大小_);
            auto [顶级概率, 顶级索引] = torch::topk(当前分布, 候选数量, 0);

            // 为每个候选创建新假设
            for (int j = 0; j < 候选数量; ++j) {
                生成假设 新假设 = 当前假设项;

                // 扩展序列
                auto 新token = 顶级索引[j].unsqueeze(0).unsqueeze(0);  // [1, 1]
                新假设.序列 = torch::cat({ 新假设.序列, 新token }, 1);

                // 更新得分（对数概率相加）
                新假设.对数概率得分 += std::log(顶级概率[j].item<float>());

                // 检查是否终止（生成结束符或达到最大长度）
                if (顶级索引[j].item<int64_t>() == 词汇表大小_ - 1 ||  // 假设最后一个token是结束符
                    新假设.序列.size(1) >= 配置.最大生成长度) {
                    新假设.已终止 = true;
                }

                新假设列表.push_back(std::move(新假设));
            }

            // 移动到下一个活跃假设
            while (原始索引 < 当前假设.size() && !当前假设[原始索引].已终止) {
                原始索引++;
            }
        }

        TORCH_INFO("束搜索迭代完成，生成新假设数量: ", 新假设列表.size());

        return 新假设列表;
    }

    // ============================================================
    // 计算下一个token概率分布
    // ============================================================

    torch::Tensor 状态空间递归生成器::计算下一个token概率(
        const torch::Tensor& 隐状态,
        const 生成配置& 配置) {

        TORCH_CHECK(隐状态.defined(), "隐状态未定义");
        TORCH_CHECK(隐状态.dim() == 2, "隐状态必须是2维 [批, 状态维度]");
        TORCH_CHECK(隐状态.size(1) == 状态维度_, "隐状态维度不匹配");

        // 1. 通过输出投影层计算logits
        // [批, 状态维度] -> [批, 词汇表大小]
        auto logits = 输出投影层_(隐状态);

        TORCH_CHECK(logits.defined(), "输出投影层前向传播失败");
        TORCH_CHECK(logits.size(1) == 词汇表大小_, "logits维度不匹配");

        // 2. 应用温度参数
        if (配置.温度 > 0 && std::abs(配置.温度 - 1.0f) > 1e-6) {
            logits /= 配置.温度;
        }

        // 3. 应用核采样（top-p）或top-k
        if (配置.使用核采样) {
            // 核采样实现：累积概率超过阈值时截断
            auto 排序概率 = torch::softmax(logits, -1);
            auto 排序值 = std::get<0>(torch::sort(排序概率, -1, true));
            auto 排序索引 = std::get<1>(torch::sort(排序概率, -1, true));

            auto 累积和 = torch::cumsum(排序值, -1);
            auto 掩码 = 累积和 > 配置.核采样概率;

            // 创建修改后的logits
            auto 修改后的logits = logits.clone();
            修改后的logits.index_fill_(-1, 排序索引[掩码], -std::numeric_limits<float>::infinity());

            logits = 修改后的logits;
        }

        // 4. 转换为概率分布
        auto 概率分布 = torch::softmax(logits, -1);

        TORCH_CHECK(!torch::isnan(概率分布).any().item<bool>(),
            "概率分布包含NaN值");
        TORCH_CHECK(!torch::isinf(概率分布).any().item<bool>(),
            "概率分布包含Inf值");

        return 概率分布;
    }

    // ============================================================
    // 应用重复惩罚 - 防止生成重复内容
    // ============================================================

    void 状态空间递归生成器::应用重复惩罚(
        torch::Tensor& 概率分布,
        const torch::Tensor& 历史序列) {

        TORCH_CHECK(概率分布.defined(), "概率分布未定义");
        TORCH_CHECK(历史序列.defined(), "历史序列未定义");

        if (历史序列.size(1) == 0) return;  // 没有历史序列

        // 统计历史序列中每个token的出现次数
        auto 历史token = 历史序列.flatten().to(torch::kInt64);
        auto 重复计数 = torch::zeros_like(概率分布);

        for (int i = 0; i < 重复计数.size(0); ++i) {
            auto 匹配 = (历史token == i);
            重复计数[i] = 匹配.sum().to(torch::kFloat32);
        }

        // 应用重复惩罚：p' = p / (重复次数 ^ 惩罚系数)
        float 惩罚系数 = 1.2f;  // 可配置
        auto 惩罚因子 = torch::pow(重复计数 + 1.0f, 惩罚系数);
        概率分布 /= 惩罚因子;

        // 重新归一化
        概率分布 /= 概率分布.sum();

        TORCH_INFO("应用重复惩罚，分布总和: ", 概率分布.sum().item<float>());
    }

    // ============================================================
    // 计算频域一致性评分
    // ============================================================

    torch::Tensor 状态空间递归生成器::计算频域一致性评分(
        const torch::Tensor& 生成序列) {

        TORCH_CHECK(生成序列.defined(), "生成序列未定义");
        TORCH_CHECK(生成序列.dim() == 2, "生成序列应为2维 [长度, 维度]");

        // 将序列转换到频域
        auto 频域表示 = torch::fft_rfft(生成序列, 生成序列.size(0), 0);

        // 计算能量谱
        auto 能量谱 = torch::abs(频域表示).pow(2);

        // 计算低频与高频能量比值
        int64_t 低频分界 = 能量谱.size(0) / 10;  // 前10%为低频

        if (低频分界 <= 0) {
            return torch::tensor(1.0f);
        }

        auto 低频能量 = 能量谱.narrow(0, 0, 低频分界).sum();
        auto 高频能量 = 能量谱.narrow(0, 低频分界, 能量谱.size(0) - 低频分界).sum() + 1e-8;

        auto 一致性比率 = 低频能量 / 高频能量;

        // 使用sigmoid映射到[0,1]区间
        return torch::sigmoid(一致性比率);
    }

    // ============================================================
    // 压缩隐状态 - 内存优化
    // ============================================================

    torch::Tensor 状态空间递归生成器::压缩隐状态(
        const torch::Tensor& 原始状态) {

        TORCH_CHECK(原始状态.defined(), "原始状态未定义");

        if (原始状态.size(1) <= 64) {
            // 状态维度已经很小，不需要压缩
            return 原始状态;
        }

        // 使用SVD进行低秩近似
        auto [U, S, V] = torch::svd(原始状态);

        // 保留前80%的能量
        auto 累积能量 = torch::cumsum(S, 0);
        auto 总能量 = S.sum();
        auto 保留维度张量 = (累积能量 < 0.8f * 总能量).sum();
        int 保留维度 = 保留维度张量.item<int>();

        // 至少保留32维
        保留维度 = std::max(保留维度, 32);
        保留维度 = std::min(保留维度, static_cast<int>(原始状态.size(1)));

        // 重建压缩后的状态
        auto 压缩状态 = torch::matmul(U.narrow(1, 0, 保留维度),
            torch::diag(S.narrow(0, 0, 保留维度)));
        压缩状态 = torch::matmul(压缩状态, V.narrow(0, 0, 保留维度).transpose(0, 1));

        TORCH_INFO("隐状态压缩完成，维度从 ", 原始状态.size(1), " 压缩到 ", 保留维度);

        return 压缩状态;
    }

    // ============================================================
    // 计算动态束宽
    // ============================================================

    int 状态空间递归生成器::计算动态束宽(
        int 当前长度,
        int 最大长度) {

        float 进度 = static_cast<float>(当前长度) / 最大长度;

        if (进度 < 0.3f) {
            // 初期：探索阶段，束宽加倍
            return 配置_.束宽 * 2;
        }
        else if (进度 > 0.7f) {
            // 后期：利用阶段，束宽减半
            return std::max(配置_.束宽 / 2, 1);
        }
        else {
            // 中期：标准束宽
            return 配置_.束宽;
        }
    }

    // ============================================================
    // 频域生成优化器 - 静态方法实现
    // ============================================================

    torch::Tensor 频域生成优化器::预计算频域基础(
        int 序列长度,
        const torch::Tensor& 频率向量) {

        TORCH_CHECK(频率向量.defined(), "频率向量未定义");

        int64_t 频率数量 = 序列长度 / 2 + 1;
        int64_t 模型维度 = 频率向量.numel();  // 这里假设频率向量的大小就是模型维度

        // 预计算复指数基函数：e^(-j·2π·k·n/N)
        auto n = torch::arange(序列长度,
            torch::TensorOptions().dtype(torch::kFloat32)
            .device(频率向量.device()));

        std::vector<torch::Tensor> 基函数列表;

        for (int64_t k = 0; k < 频率数量; ++k) {
            auto 当前频率 = 频率向量[k].item<float>();

            // 修正复数单位定义
            auto j = torch::tensor({ 0.0f, 1.0f },
                torch::TensorOptions().dtype(torch::kComplexFloat).device(频率向量.device()));
            auto 复数单位 = j.sum();  // 创建一个复数标量 (0+1j)

            auto 复指数 = torch::exp(-复数单位 * 2 * M_PI * 当前频率 * n / 序列长度);
            基函数列表.push_back(复指数.unsqueeze(0));
        }

        auto 基函数矩阵 = torch::cat(基函数列表, 0);

        TORCH_INFO("频域基础缓存预计算完成，形状: ", 基函数矩阵.sizes());

        return 基函数矩阵;
    }

    // ============================================================
    // 频域缓存管理器 - 更新缓存
    // ============================================================

    void 频域生成优化器::频域缓存管理器::更新缓存(
        const torch::Tensor& 新序列部分) {

        TORCH_CHECK(新序列部分.defined(), "新序列部分未定义");

        if (!频域缓存_.defined()) {
            // 首次初始化缓存
            频域缓存_ = torch::fft_rfft(新序列部分, 新序列部分.size(0), 0);
            当前序列长度_ = 新序列部分.size(0);
            return;
        }

        // 增量更新已有缓存
        auto 增量结果 = 频域生成优化器::增量快速傅里叶变换(
            新序列部分,
            频域缓存_,
            当前序列长度_
        );

        频域缓存_ = 增量结果;
        当前序列长度_ += 新序列部分.size(0);

        // 环形缓冲区管理：如果超过最大长度，复用空间
        if (当前序列长度_ > 最大缓存长度_) {
            当前序列长度_ = 最大缓存长度_;
            环形写入位置_ = (环形写入位置_ + 新序列部分.size(0)) % 最大缓存长度_;
        }
    }

    // ============================================================
    // 频域缓存管理器 - 清空缓存
    // ============================================================

    void 频域生成优化器::频域缓存管理器::清空缓存() {
        频域缓存_ = torch::Tensor();
        当前序列长度_ = 0;
        环形写入位置_ = 0;
    }

} // namespace SpectraSSM